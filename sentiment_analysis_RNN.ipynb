{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  RNN - Sentiment Analysis  based on Keras\n",
    "\n",
    "Here, not like the language model, each sequence has only one label. It is a sequence classifciation model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"         # 3 is can change to 0-3\n",
    "\n",
    "from tensorflow import keras\n",
    "sequence = keras.preprocessing.sequence\n",
    "Sequential = keras.models.Sequential\n",
    "Dense = keras.layers.Dense\n",
    "Embedding = keras.layers.Embedding\n",
    "LSTM = keras.layers.LSTM\n",
    "imdb = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 128\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sub sample date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train = x_train[:2000]\n",
    "# y_train = y_train[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_test = x_test[:500]\n",
    "# y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 80)\n",
      "x_test shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Sequential model to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 30s 1ms/step - loss: 0.5037 - acc: 0.7516 - val_loss: 0.4071 - val_acc: 0.8225\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.3165 - acc: 0.8729 - val_loss: 0.3738 - val_acc: 0.8358\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.2494 - acc: 0.9029 - val_loss: 0.4062 - val_acc: 0.8222\n",
      "25000/25000 [==============================] - 5s 218us/step\n",
      "Test accuracy: 0.822240000038147\n"
     ]
    }
   ],
   "source": [
    "# print('Build model...')\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 50))\n",
    "# model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # try using different optimizers and different optimizer configs\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "# print('Train...')\n",
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=batch_size,\n",
    "#           epochs=3,\n",
    "#           validation_data=(x_test, y_test))\n",
    "# score, acc = model.evaluate(x_test, y_test,\n",
    "#                             batch_size=batch_size)\n",
    "# print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model class used with functional API\n",
    "\n",
    "1. define input and target layer\n",
    "2. call models to set input and target\n",
    "3. layers are used to connect between input and target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Model = keras.models.Model\n",
    "Input = keras.layers.Input\n",
    "Dense = keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embed)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 33s 1ms/step - loss: 0.5044 - acc: 0.7520 - val_loss: 0.4189 - val_acc: 0.8075\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 32s 1ms/step - loss: 0.3172 - acc: 0.8735 - val_loss: 0.3700 - val_acc: 0.8421\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 32s 1ms/step - loss: 0.2526 - acc: 0.9018 - val_loss: 0.3955 - val_acc: 0.8325\n",
      "25000/25000 [==============================] - 7s 294us/step\n",
      "Test accuracy: 0.8325199999809265\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(hidden_layer_one)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer_two)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 65s 3ms/step - loss: 0.4937 - acc: 0.7470 - val_loss: 0.3749 - val_acc: 0.8340\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 60s 2ms/step - loss: 0.3001 - acc: 0.8783 - val_loss: 0.4040 - val_acc: 0.8305\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 62s 2ms/step - loss: 0.2298 - acc: 0.9124 - val_loss: 0.4941 - val_acc: 0.8144\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 61s 2ms/step - loss: 0.1870 - acc: 0.9314 - val_loss: 0.4263 - val_acc: 0.8266\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 61s 2ms/step - loss: 0.1553 - acc: 0.9451 - val_loss: 0.4942 - val_acc: 0.8176\n",
      "25000/25000 [==============================] - 14s 573us/step\n",
      "Test accuracy: 0.8176400000190734\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bidrectional LSTM\n",
    "```\n",
    "keras.layers.Bidirectional(layer, merge_mode='concat', weights=None)\n",
    "```\n",
    "layer: Recurrent instance.\n",
    "merge_mode: Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Bidirectional = keras.layers.Bidirectional\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(hidden_layer_one)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer_two)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 93s 4ms/step - loss: 0.4654 - acc: 0.7627 - val_loss: 0.3732 - val_acc: 0.8338\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 89s 4ms/step - loss: 0.2869 - acc: 0.8852 - val_loss: 0.3731 - val_acc: 0.8356\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 88s 4ms/step - loss: 0.2068 - acc: 0.9218 - val_loss: 0.4203 - val_acc: 0.8317\n",
      "25000/25000 [==============================] - 21s 820us/step\n",
      "Test score: 0.42030117997169497\n",
      "Test accuracy: 0.831719999961853\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LSTM hiddent average vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "K = keras.backend\n",
    "Lambda = keras.layers.Lambda\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(hidden_layer_one)\n",
    "final_vector = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_two)\n",
    "target = Dense(1, activation='sigmoid')(final_vector)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 64s 3ms/step - loss: 0.4895 - acc: 0.7614 - val_loss: 0.4022 - val_acc: 0.8209\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 63s 3ms/step - loss: 0.3020 - acc: 0.8739 - val_loss: 0.4096 - val_acc: 0.8220\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 62s 2ms/step - loss: 0.2271 - acc: 0.9098 - val_loss: 0.4472 - val_acc: 0.8100\n",
      "25000/25000 [==============================] - 14s 572us/step\n",
      "Test accuracy: 0.8099999999809265\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LSTM concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "Lambda = keras.layers.Lambda\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(hidden_layer_one)\n",
    "final_vector1 = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_two)\n",
    "final_vector2 = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_one)\n",
    "final_vector = keras.layers.Average()([final_vector1, final_vector2])\n",
    "target = Dense(1, activation='sigmoid')(final_vector)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admusr/anaconda2/envs/python3_pengfei/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:112: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 66s 3ms/step - loss: 0.5127 - acc: 0.7410 - val_loss: 0.4092 - val_acc: 0.8184\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 62s 2ms/step - loss: 0.3103 - acc: 0.8699 - val_loss: 0.4449 - val_acc: 0.8113\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 62s 2ms/step - loss: 0.2344 - acc: 0.9059 - val_loss: 0.4874 - val_acc: 0.7903\n",
      "25000/25000 [==============================] - 15s 587us/step\n",
      "Test accuracy: 0.7902800000190735\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
