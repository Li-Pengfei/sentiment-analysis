{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  RNN - Sentiment Analysis  based on Keras\n",
    "\n",
    "Here, not like the language model, each sequence has only one label. It is a sequence classifciation model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "sequence = keras.preprocessing.sequence\n",
    "Sequential = keras.models.Sequential\n",
    "Dense = keras.layers.Dense\n",
    "Embedding = keras.layers.Embedding\n",
    "LSTM = keras.layers.LSTM\n",
    "imdb = keras.datasets.imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 128\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sub sample date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train[:2000]\n",
    "y_train = y_train[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 0, 1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test[:500]\n",
    "y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000 train sequences\n",
      "500 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (2000, 80)\n",
      "x_test shape: (500, 80)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Sequential model to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 6s 3ms/step - loss: 0.6926 - acc: 0.5085 - val_loss: 0.6915 - val_acc: 0.4960\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 5s 2ms/step - loss: 0.6716 - acc: 0.6090 - val_loss: 0.6388 - val_acc: 0.6560\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 4s 2ms/step - loss: 0.5552 - acc: 0.7735 - val_loss: 0.5599 - val_acc: 0.7660\n",
      "500/500 [==============================] - 0s 559us/step\n",
      "Test accuracy: 0.7659999976158142\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 50))\n",
    "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# try using different optimizers and different optimizer configs\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Model class used with functional API\n",
    "\n",
    "1. define input and target layer\n",
    "2. call models to set input and target\n",
    "3. layers are used to connect between input and target layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = keras.models.Model\n",
    "Input = keras.layers.Input\n",
    "Dense = keras.layers.Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(embed)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6852 - acc: 0.5745 - val_loss: 0.6307 - val_acc: 0.7220\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.5803 - acc: 0.7315 - val_loss: 0.6181 - val_acc: 0.6520\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 12s 6ms/step - loss: 0.3862 - acc: 0.8390 - val_loss: 0.5087 - val_acc: 0.7640\n",
      "500/500 [==============================] - 0s 862us/step\n",
      "Test score: 0.5086510560512543\n",
      "Test accuracy: 0.764\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  stacked LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2)(hidden_layer_one)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer_two)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 28s 14ms/step - loss: 0.6867 - acc: 0.5445 - val_loss: 0.6297 - val_acc: 0.6740\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 28s 14ms/step - loss: 0.4544 - acc: 0.7950 - val_loss: 0.5230 - val_acc: 0.7580\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 23s 12ms/step - loss: 0.1629 - acc: 0.9420 - val_loss: 0.5969 - val_acc: 0.7940\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 22s 11ms/step - loss: 0.0645 - acc: 0.9785 - val_loss: 0.8957 - val_acc: 0.7380\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 24s 12ms/step - loss: 0.0473 - acc: 0.9850 - val_loss: 0.9473 - val_acc: 0.7580\n",
      "500/500 [==============================] - 1s 2ms/step\n",
      "Test score: 0.947280821800232\n",
      "Test accuracy: 0.7579999990463256\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bidrectional LSTM\n",
    "```\n",
    "keras.layers.Bidirectional(layer, merge_mode='concat', weights=None)\n",
    "```\n",
    "layer: Recurrent instance.\n",
    "merge_mode: Mode by which outputs of the forward and backward RNNs will be combined. One of {'sum', 'mul', 'concat', 'ave', None}. If None, the outputs will not be combined, they will be returned as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bidirectional = keras.layers.Bidirectional\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=0.2))(hidden_layer_one)\n",
    "target = Dense(1, activation='sigmoid')(hidden_layer_two)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "2000/2000 [==============================] - 37s 19ms/step - loss: 0.6832 - acc: 0.5385 - val_loss: 0.6172 - val_acc: 0.6760\n",
      "Epoch 2/5\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.4333 - acc: 0.8065 - val_loss: 0.4552 - val_acc: 0.7920\n",
      "Epoch 3/5\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.1874 - acc: 0.9275 - val_loss: 0.5386 - val_acc: 0.7520\n",
      "Epoch 4/5\n",
      "2000/2000 [==============================] - 34s 17ms/step - loss: 0.0740 - acc: 0.9755 - val_loss: 0.7045 - val_acc: 0.7660\n",
      "Epoch 5/5\n",
      "2000/2000 [==============================] - 37s 19ms/step - loss: 0.0320 - acc: 0.9910 - val_loss: 0.8478 - val_acc: 0.7640\n",
      "500/500 [==============================] - 1s 3ms/step\n",
      "Test score: 0.8478314962387085\n",
      "Test accuracy: 0.7640000004768371\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LSTM hiddent average vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "K = keras.backend\n",
    "Lambda = keras.layers.Lambda\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(hidden_layer_one)\n",
    "final_vector = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_two)\n",
    "target = Dense(1, activation='sigmoid')(final_vector)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6926 - acc: 0.5225 - val_loss: 0.6941 - val_acc: 0.4760\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.6382 - acc: 0.6130 - val_loss: 0.5868 - val_acc: 0.7160\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 11s 5ms/step - loss: 0.4123 - acc: 0.8490 - val_loss: 0.5770 - val_acc: 0.7180\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Test score: 0.5769503536224365\n",
      "Test accuracy: 0.7180000052452088\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  LSTM concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = keras.backend\n",
    "Lambda = keras.layers.Lambda\n",
    "input_a = Input(shape=(maxlen,))\n",
    "embed = Embedding(max_features, 50)(input_a)\n",
    "hidden_layer_one = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(embed)\n",
    "hidden_layer_two = LSTM(128, dropout=0.2, recurrent_dropout=0.2, return_sequences=True)(hidden_layer_one)\n",
    "final_vector1 = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_two)\n",
    "final_vector2 = Lambda(lambda x: K.mean(x, axis=1), output_shape=(128,))(hidden_layer_one)\n",
    "final_vector = keras.layers.Average()([final_vector1, final_vector2])\n",
    "target = Dense(1, activation='sigmoid')(final_vector)\n",
    "model = Model(inputs=input_a, outputs=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/week3/lib/python3.5/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6932 - acc: 0.4965 - val_loss: 0.6930 - val_acc: 0.4760\n",
      "Epoch 2/3\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.6563 - acc: 0.5895 - val_loss: 0.6205 - val_acc: 0.6520\n",
      "Epoch 3/3\n",
      "2000/2000 [==============================] - 13s 6ms/step - loss: 0.4512 - acc: 0.8235 - val_loss: 0.5881 - val_acc: 0.7140\n",
      "500/500 [==============================] - 1s 1ms/step\n",
      "Test score: 0.5880889921188355\n",
      "Test accuracy: 0.7140000004768372\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=3,\n",
    "          validation_data=(x_test, y_test))\n",
    "score, acc = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
