{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence\n",
    "* 获取数据\n",
    "* 搭建神经网络 sequential().add()\n",
    "* 编译神经网络 compile()\n",
    "* 训练神经网络 fit()\n",
    "* 评估神经网络 evalue()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unfamiliar concepts\n",
    "* filter: 相当于一个matrix，维度为（想要输出的维度*（词的维度*词的个数））\n",
    "* pool_size 池化窗口的大小，图 in brain\n",
    "* pooling: extracting some feature \n",
    "* local feature\n",
    "* CNN->抓取情感词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten, Embedding,MaxPooling1D\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "#to get the data,the number of the data is 25000\n",
    "#x_train中的是一组list，一个list是一个影评，里面的每个词是用它出现的频率从1-num_words，那这个list一得出来就是一组数\n",
    "#y_train中的是一组list，一个list代表的是这个影评的极性（0 or 1）\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:5000]\n",
    "y_train = y_train[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test[:500]\n",
    "y_test = y_test[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 train sequences\n",
      "500 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (5000, 80)\n",
      "x_test shape: (500, 80)\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "#0做padding\n",
    "#maxlen根据文本来定\n",
    "#x_train is the list which is waiting for being cutted as the maxlen\n",
    "#maxlen is the maxim length of list\n",
    "#return a numpy matrix(length * maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Train...\n",
      "Train on 5000 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "5000/5000 [==============================] - 7s 1ms/step - loss: 0.6935 - acc: 0.4930 - val_loss: 0.6887 - val_acc: 0.6080\n",
      "Epoch 2/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.5468 - acc: 0.7544 - val_loss: 0.5143 - val_acc: 0.7640\n",
      "Epoch 3/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.2045 - acc: 0.9224 - val_loss: 0.4372 - val_acc: 0.8120\n",
      "Epoch 4/5\n",
      "5000/5000 [==============================] - 6s 1ms/step - loss: 0.0391 - acc: 0.9922 - val_loss: 0.5167 - val_acc: 0.8200\n",
      "Epoch 5/5\n",
      "5000/5000 [==============================] - 5s 1ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.8100\n",
      "500/500 [==============================] - 0s 207us/step\n",
      "Test accuracy: [0.6015336561203003, 0.8099999947547912]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#记录baseline algorithm\n",
    "\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "#follow the sequence to create the model\n",
    "\n",
    "model.add(Embedding(max_features, 32, input_length = maxlen))\n",
    "#max_feature->词汇表大小\n",
    "#I consider the max_features vocabulary\n",
    "#use 32 dimension to represent each word\n",
    "#the length of every review is maxlen\n",
    "\n",
    "model.add(Conv1D(filters = 64, kernel_size = 3, padding = 'same',activation = 'relu'))\n",
    "#************************对卷积层的维度不了解\n",
    "#filters: 整数，输出空间的维度 （即卷积中滤波器的输出数量）\n",
    "#kernel_size: 一个整数，或者单个整数表示的元组或列表， 指明 1D 卷积窗口的长度\n",
    "#\"same\" 表示填充输入以使输出的和原始输入的那个长度相等\n",
    "\n",
    "model.add(MaxPooling1D(pool_size = 2))#********global->number maxpooling->vector\n",
    "#Max pooling取每一个区域的最大值\n",
    "#pool_size: 整数，最大池化的窗口大小。\n",
    "model.add(Flatten())\n",
    "model.add(Dense(250, activation = 'relu'))\n",
    "model.add(Dense(125,activation = 'relu'))\n",
    "model.add(Dense(1,activation = 'sigmoid'))#dense + softmax\n",
    "#dense是创造一个全连接层，其参数为（输出数据的维度，输出数据的维度）\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print('Train...')\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(x_test, y_test))\n",
    "loss_and_metrics = model.evaluate(x_test, y_test,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 32)            640000    \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 80, 64)            6208      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 40, 64)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 250)               640250    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 125)               31375     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 126       \n",
      "=================================================================\n",
      "Total params: 1,317,959\n",
      "Trainable params: 1,317,959\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
