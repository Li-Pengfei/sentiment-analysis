{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* 获取senti words\n",
    "* 别忘了clean里面的符号（用clean代替一些代码）\n",
    "* 拿了大概五百个\n",
    "* filter weights用sent2net里的词汇\n",
    "* 从sentiwordnet,如何从文件里抓取极性词，分数大于0.8，建立两个得到list的情感词。分开positive和negative\n",
    "* 加到一个list\n",
    "* layer = return true\n",
    "\n",
    "* 自己得到cnn_filter weights\n",
    "* 默认train的时候得到weights是initilizer randomly的\n",
    "* 自己train的时候，trainable为false，因为已经得到情感词\n",
    "* weight.shape（window_size,feature_dimension(embedding),number of words/number of filter）\n",
    "* bias.shape(number of sentiment words/number of filter)一维list \n",
    "* 两个合在一起"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "* function:get the sentiment words,use the filters to get\n",
    "* input:()\n",
    "* filter:to extract some features\n",
    "* filter_length:the quantity of filters\n",
    "* max_pooling:\n",
    "* output:(batch_size*)\n",
    "* 用两个CNN，一个是knowledge的，如果没找完，就要用random了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM\n",
    "* function:\n",
    "* input:\n",
    "* output:\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# questions\n",
    "* 为什么maxpooling得到这个\n",
    "* 可以试试别的\n",
    "* filter的作用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test\n",
    "* 两个最重要的是vocab2int 和 embedding matrix\n",
    "* 纯CNN跑，用全部的数据，不用分句\n",
    "* 后面三个是以句子为单位\n",
    "* cnn layer2是基于知识的\n",
    "* 用skLearn得到recall 和precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\gensim\\utils.py:865: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Lambda\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Convolution1D, MaxPooling1D, GlobalMaxPooling1D, Input, Dense, Reshape, LSTM, GRU\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import gensim\n",
    "import numpy as np\n",
    "from util.util_functions import getWordIdx\n",
    "import nltk\n",
    "import string\n",
    "from sklearn.metrics import classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading the train_copus_padded data from .pickle file\n",
    "file = open('pickle_data/train_copus_pad.pickle','rb')\n",
    "train_copus_padded = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/test_copus_pad.pickle','rb')\n",
    "test_copus_padded = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/vocab_train.pickle','rb')\n",
    "vocab_to_int_train = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/embedding_matrix','rb')\n",
    "embedding_matrix = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/train_label.pickle','rb')\n",
    "train_label = pickle.load(file)\n",
    "\n",
    "file = open('pickle_data/test_label.pickle','rb')\n",
    "test_label = pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train test data shape: (25000, 36, 224) (25000, 36, 224)\n",
      "embedding_matrix shape: (100297, 300)\n",
      "vocabulary size: 100297\n",
      "max sent length: 36 \n",
      "max word length: 224\n"
     ]
    }
   ],
   "source": [
    "print('train test data shape:',train_copus_padded.shape, test_copus_padded.shape)\n",
    "print('embedding_matrix shape:', embedding_matrix.shape)\n",
    "#the size of vocabulary\n",
    "vocab_size = len(vocab_to_int_train)\n",
    "print('vocabulary size:', vocab_size)\n",
    "# the maximal length of every sentence\n",
    "maxlen_sent = train_copus_padded.shape[1]\n",
    "maxlen_word = train_copus_padded.shape[2]\n",
    "print('max sent length:', maxlen_sent, '\\nmax word length:', maxlen_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting sentiment words from SentiWordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = 'resource/SentiWordNet_3.0.0_20130122.txt'\n",
    "content = []\n",
    "with open(file_path,'r',encoding='UTF-8') as f:\n",
    "    while(1):\n",
    "        lines = f.readline()\n",
    "        if(lines[0] is ('a' or 'n' or 'v' or 'r')):\n",
    "            content.append(lines.split('\\t'))\n",
    "        elif(lines[0] is '#'):\n",
    "            continue\n",
    "        else:\n",
    "            break\n",
    "             \n",
    "#get the sentiment words(score>0.8)\n",
    "neg_words1 = []\n",
    "pos_words1 = []\n",
    "for lines in content:\n",
    "    if(float(lines[2])>=0.8):\n",
    "        pos_words1.append(lines[4])\n",
    "    elif(float(lines[3])>=0.8):\n",
    "        neg_words1.append(lines[4])\n",
    "\n",
    "#get the positive sentiment words\n",
    "#seperate the multiple words\n",
    "pos_words2 = []\n",
    "for i in range(len(pos_words1)):\n",
    "    pos_words2.append(pos_words1[i].split(' '))\n",
    "\n",
    "#get the one dimension elements\n",
    "pos_words3 = []\n",
    "for i in pos_words2:\n",
    "    for j in i:\n",
    "        pos_words3.append(j)\n",
    "\n",
    "#delete the '#4'\n",
    "pos_words4 = []\n",
    "for elem in pos_words3:\n",
    "    pos_words4.append(re.sub('#\\d','',elem))\n",
    "    \n",
    "#delete the 'number'\n",
    "pos_lexicon = []\n",
    "for elem in pos_words4:\n",
    "    pos_lexicon.append(re.sub('\\d','',elem))\n",
    "\n",
    "    \n",
    "#get the negative sentiment words\n",
    "#seperate the multiple words\n",
    "neg_words2 = []\n",
    "for i in range(len(neg_words1)):\n",
    "    neg_words2.append(neg_words1[i].split(' '))\n",
    "\n",
    "#get the one dimension elements\n",
    "neg_words3 = []\n",
    "for i in neg_words2:\n",
    "    for j in i:\n",
    "        neg_words3.append(j)\n",
    "\n",
    "#delete the '#4'\n",
    "neg_words4 = []\n",
    "for elem in neg_words3:\n",
    "    neg_words4.append(re.sub('#\\d','',elem))\n",
    "    \n",
    "#delete the 'number'\n",
    "neg_lexicon = []\n",
    "for elem in neg_words4:\n",
    "    neg_lexicon.append(re.sub('\\d','',elem))\n",
    "\n",
    "#merge the positive and negative words\n",
    "senti_lexicon = pos_lexicon + neg_lexicon\n",
    "#shuffule the these lists\n",
    "from sklearn.utils import shuffle \n",
    "senti_lexicon = shuffle(senti_lexicon,random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['nifty',\n",
       " 'swingeing',\n",
       " 'low',\n",
       " 'spastic',\n",
       " 'ill-famed',\n",
       " 'negative',\n",
       " 'depressed',\n",
       " 'banner',\n",
       " 'condemnable',\n",
       " 'rosy-cheeked',\n",
       " 'spasmodic',\n",
       " 'unforbearing',\n",
       " 'perverted',\n",
       " 'kind',\n",
       " 'scrimy',\n",
       " 'plain',\n",
       " 'woebegone',\n",
       " 'lamentable',\n",
       " 'idealized',\n",
       " 'substitute',\n",
       " 'splendid',\n",
       " 'unlikable',\n",
       " 'awe-inspiring',\n",
       " 'wretched',\n",
       " 'henpecked',\n",
       " 'denigrating',\n",
       " 'cheesy',\n",
       " 'aesthetic',\n",
       " 'mild',\n",
       " 'ruthless',\n",
       " 'tall',\n",
       " 'faux',\n",
       " 'inerrable',\n",
       " 'thoroughgoing',\n",
       " 'imitation',\n",
       " 'fake',\n",
       " 'burned',\n",
       " 'atrocious',\n",
       " 'censurable',\n",
       " 'dominated',\n",
       " 'deplorable',\n",
       " 'dewy-eyed',\n",
       " 'fearful',\n",
       " 'gross',\n",
       " 'preternatural',\n",
       " 'inapposite',\n",
       " 'pretty',\n",
       " 'rugged',\n",
       " 'pitiful',\n",
       " 'firm',\n",
       " 'infamous',\n",
       " 'neat',\n",
       " 'mucky',\n",
       " 'sheltered',\n",
       " 'poor',\n",
       " 'inspired',\n",
       " 'uncivil',\n",
       " 'unhealthy',\n",
       " 'scurrilous',\n",
       " 'clean-living',\n",
       " 'sorry',\n",
       " 'musty',\n",
       " 'unfriendly',\n",
       " 'greasy',\n",
       " 'deplorable',\n",
       " 'healing',\n",
       " 'diabolic',\n",
       " 'burned-out',\n",
       " 'malodourous',\n",
       " 'righteous',\n",
       " 'vixenish',\n",
       " 'charming',\n",
       " 'miserable',\n",
       " 'ill-smelling',\n",
       " 'unthreatening',\n",
       " 'wretched',\n",
       " 'infuriating',\n",
       " 'fantabulous',\n",
       " 'untreated',\n",
       " 'fabulous',\n",
       " 'of_import',\n",
       " 'superb',\n",
       " 'cross-grained',\n",
       " 'nontraditional',\n",
       " 'right',\n",
       " 'salubrious',\n",
       " 'better',\n",
       " 'esthetic',\n",
       " 'sheer',\n",
       " 'verminous',\n",
       " 'ill',\n",
       " 'homological',\n",
       " 'distressful',\n",
       " 'lecherous',\n",
       " 'dignifying',\n",
       " 'out',\n",
       " 'cataclysmal',\n",
       " 'hardhearted',\n",
       " 'unmingled',\n",
       " 'insubordinate',\n",
       " 'blue',\n",
       " 'scummy',\n",
       " 'terrible',\n",
       " 'avirulent',\n",
       " 'benign',\n",
       " 'bush',\n",
       " 'undeniable',\n",
       " 'simulated',\n",
       " 'cataclysmic',\n",
       " 'cretinous',\n",
       " 'remedial',\n",
       " 'blameable',\n",
       " 'false',\n",
       " 'self-respecting',\n",
       " 'malodorous',\n",
       " 'disagreeable',\n",
       " 'artful',\n",
       " 'upset',\n",
       " 'transcendental',\n",
       " 'straightarrow',\n",
       " 'laid_up',\n",
       " 'self-respectful',\n",
       " 'thunderous',\n",
       " 'engaging',\n",
       " 'good',\n",
       " 'sallow',\n",
       " 'out_of_place',\n",
       " 'nonstandard',\n",
       " 'wretched',\n",
       " 'worried',\n",
       " 'inflamed',\n",
       " 'ennobling',\n",
       " 'clean',\n",
       " 'miserable',\n",
       " 'bang-up',\n",
       " 'bounden',\n",
       " 'cantankerous',\n",
       " 'great',\n",
       " 'good',\n",
       " 'satanic',\n",
       " 'downcast',\n",
       " 'roofless',\n",
       " 'solid',\n",
       " 'gainly',\n",
       " 'piquant',\n",
       " 'pretty',\n",
       " 'heartless',\n",
       " 'comfortless',\n",
       " 'soft-boiled',\n",
       " 'good_for_you',\n",
       " 'irrefutable',\n",
       " 'inferior',\n",
       " 'dismissive',\n",
       " 'libellous',\n",
       " 'burnt',\n",
       " 'unerring',\n",
       " 'denigrative',\n",
       " 'unpeaceable',\n",
       " 'decent',\n",
       " 'artistic',\n",
       " 'pathetic',\n",
       " 'goody-goody',\n",
       " 'glacial',\n",
       " 'painful',\n",
       " 'criminal',\n",
       " 'occult',\n",
       " 'untraditional',\n",
       " 'humble',\n",
       " 'good_enough',\n",
       " 'ungratified',\n",
       " 'stinky',\n",
       " 'perturbing',\n",
       " 'quaint',\n",
       " 'calumnious',\n",
       " 'denigratory',\n",
       " 'convulsive',\n",
       " 'unfortunate',\n",
       " 'corking',\n",
       " 'flushed',\n",
       " 'fortunate',\n",
       " 'unfortunate',\n",
       " 'miserable',\n",
       " 'disagreeable',\n",
       " 'perked_up',\n",
       " 'unaccepted',\n",
       " 'bedraggled',\n",
       " 'low-spirited',\n",
       " 'grotty',\n",
       " 'attractive',\n",
       " 'brilliant',\n",
       " 'unholy',\n",
       " 'olympian',\n",
       " 'harsh',\n",
       " 'diffident',\n",
       " 'rude',\n",
       " 'alterative',\n",
       " 'courteous',\n",
       " 'scrofulous',\n",
       " 'soft',\n",
       " 'improper',\n",
       " 'uncool',\n",
       " 'ungrateful',\n",
       " 'strong',\n",
       " 'sanative',\n",
       " 'bum',\n",
       " 'fractious',\n",
       " 'well-thought-of',\n",
       " 'joking',\n",
       " 'remorseless',\n",
       " 'abusive',\n",
       " 'monstrous',\n",
       " 'low',\n",
       " 'upset',\n",
       " 'mussy',\n",
       " 'worthy',\n",
       " 'distressed',\n",
       " 'ersatz',\n",
       " 'troublesome',\n",
       " 'troubled',\n",
       " 'softhearted',\n",
       " 'outrageous',\n",
       " 'cracking',\n",
       " 'wretched',\n",
       " 'snotty',\n",
       " 'respectable',\n",
       " 'notorious',\n",
       " 'contrarious',\n",
       " 'minus',\n",
       " 'admirable',\n",
       " 'unfit',\n",
       " 'therapeutic',\n",
       " 'atrocious',\n",
       " 'tinny',\n",
       " 'filthy',\n",
       " 'small',\n",
       " 'poor',\n",
       " 'burnt-out',\n",
       " 'cheap',\n",
       " 'indifferent',\n",
       " 'knocked-out',\n",
       " 'downhearted',\n",
       " 'awesome',\n",
       " 'pestilent',\n",
       " 'angry',\n",
       " 'libelous',\n",
       " 'intellectual',\n",
       " 'lowly',\n",
       " 'messy',\n",
       " 'defamatory',\n",
       " 'undivided',\n",
       " 'formidable',\n",
       " 'thorough',\n",
       " 'disconfirming',\n",
       " 'discrepant',\n",
       " 'excellent',\n",
       " 'healthy',\n",
       " 'topping',\n",
       " 'divine',\n",
       " 'rubbishy',\n",
       " 'sore',\n",
       " 'abject',\n",
       " 'culpable',\n",
       " 'exasperating',\n",
       " 'selfless',\n",
       " 'low',\n",
       " 'superlative',\n",
       " 'tough',\n",
       " 'abominable',\n",
       " 'dignified',\n",
       " 'antisocial',\n",
       " 'unauthorized',\n",
       " 'resentful',\n",
       " 'severe',\n",
       " 'dishonorable',\n",
       " 'icy',\n",
       " 'majestic',\n",
       " 'woeful',\n",
       " 'unhappy',\n",
       " 'grievous',\n",
       " 'opprobrious',\n",
       " 'unpitying',\n",
       " 'dysphoric',\n",
       " 'positive',\n",
       " 'childlike',\n",
       " 'estimable',\n",
       " 'awful',\n",
       " 'not_bad',\n",
       " 'gracious',\n",
       " 'rank',\n",
       " 'distressing',\n",
       " 'invalidating',\n",
       " 'afflictive',\n",
       " 'hellish',\n",
       " 'censorious',\n",
       " 'rose-cheeked',\n",
       " 'dreadful',\n",
       " 'worthy',\n",
       " 'distressing',\n",
       " 'discerning',\n",
       " 'smart',\n",
       " 'blamable',\n",
       " 'shoddy',\n",
       " 'uncorrupted',\n",
       " 'gladdened',\n",
       " 'frigid',\n",
       " 'crotchety',\n",
       " 'virtuous',\n",
       " 'disingenuous',\n",
       " 'brokenhearted',\n",
       " 'brag',\n",
       " 'reprobate',\n",
       " 'idealised',\n",
       " 'harsh',\n",
       " 'lugubrious',\n",
       " 'vexing',\n",
       " 'depraved',\n",
       " 'underivative',\n",
       " 'muddy',\n",
       " 'perverse',\n",
       " 'unacceptable',\n",
       " 'crying',\n",
       " 'incontrovertible',\n",
       " 'unreliable',\n",
       " 'curative',\n",
       " 'blessed',\n",
       " 'unspoiled',\n",
       " 'sad',\n",
       " 'gloomy',\n",
       " 'wide-eyed',\n",
       " 'constructive',\n",
       " 'algophobic',\n",
       " 'unsound',\n",
       " 'uncontrollable',\n",
       " 'swell',\n",
       " 'pitiable',\n",
       " 'pitiless',\n",
       " 'genial',\n",
       " 'troubling',\n",
       " 'bad',\n",
       " 'ill-natured',\n",
       " 'better',\n",
       " 'frowsty',\n",
       " 'demonic',\n",
       " 'reprehensible',\n",
       " 'low-down',\n",
       " 'dispirited',\n",
       " 'rare',\n",
       " 'jocose',\n",
       " 'honorable',\n",
       " 'golden',\n",
       " 'sweet',\n",
       " 'spiffing',\n",
       " 'top-flight',\n",
       " 'balmy',\n",
       " 'hideous',\n",
       " 'churlish',\n",
       " 'fab',\n",
       " 'broken-down',\n",
       " 'boss',\n",
       " 'burned-over',\n",
       " 'undependable',\n",
       " 'unsound',\n",
       " 'wicked',\n",
       " 'flagitious',\n",
       " 'fiendish',\n",
       " 'unmixed',\n",
       " 'scurvy',\n",
       " 'punk',\n",
       " 'unpainted',\n",
       " 'exhaustive',\n",
       " 'ornery',\n",
       " 'awful',\n",
       " 'vicious',\n",
       " 'homeless',\n",
       " 'disturbing',\n",
       " 'down_in_the_mouth',\n",
       " 'abusive',\n",
       " 'altruistic',\n",
       " 'awful',\n",
       " 'answerable',\n",
       " 'unpleasant-smelling',\n",
       " 'fusty',\n",
       " 'homologic',\n",
       " 'nasty',\n",
       " 'well-meaning',\n",
       " 'baneful',\n",
       " 'disturbed',\n",
       " 'piteous',\n",
       " 'painful',\n",
       " 'crummy',\n",
       " 'fouled',\n",
       " 'miserable',\n",
       " 'amicable',\n",
       " 'horrid',\n",
       " 'inextinguishable',\n",
       " 'unsurpassable',\n",
       " 'worrisome',\n",
       " 'nonnatural',\n",
       " 'important',\n",
       " 'unfortunate',\n",
       " 'better_off',\n",
       " 'fireproof',\n",
       " 'good',\n",
       " 'smashing',\n",
       " 'dispossessed',\n",
       " 'dandy',\n",
       " 'restless',\n",
       " 'limited',\n",
       " 'imponderable',\n",
       " 'asocial',\n",
       " 'nice',\n",
       " 'grim',\n",
       " 'happy',\n",
       " 'creepy',\n",
       " 'frosty',\n",
       " 'simple',\n",
       " 'oily',\n",
       " 'blest',\n",
       " 'unsympathetic',\n",
       " 'peachy',\n",
       " 'bush-league',\n",
       " 'rough',\n",
       " 'veracious',\n",
       " 'blameworthy',\n",
       " 'glaring',\n",
       " 'terrible',\n",
       " 'dishonest',\n",
       " 'disquieted',\n",
       " 'incumbent',\n",
       " 'bitter',\n",
       " 'calumniatory',\n",
       " 'deplorable',\n",
       " 'otherworldly',\n",
       " 'unspeakable',\n",
       " 'malevolent',\n",
       " 'lost',\n",
       " 'distressed',\n",
       " 'legendary',\n",
       " 'incompatible',\n",
       " 'lucky',\n",
       " 'tawdry',\n",
       " 'wrong',\n",
       " 'salutary',\n",
       " 'frightful',\n",
       " 'groovy',\n",
       " 'slanderous',\n",
       " 'wintry',\n",
       " 'unlamented',\n",
       " 'unsatisfied',\n",
       " 'hapless',\n",
       " 'insufficient',\n",
       " 'down',\n",
       " 'greatest',\n",
       " 'first-class',\n",
       " 'suffering',\n",
       " 'draggled',\n",
       " 'sickly',\n",
       " 'round-eyed',\n",
       " 'execrable',\n",
       " 'keen',\n",
       " 'negative',\n",
       " 'inerrant',\n",
       " 'diabolical',\n",
       " 'egregious',\n",
       " 'jesting',\n",
       " 'deadly',\n",
       " 'respected',\n",
       " 'trashy',\n",
       " 'sleazy',\n",
       " 'unmanageable',\n",
       " 'unlikeable',\n",
       " 'blameful',\n",
       " 'amazing',\n",
       " 'jocular',\n",
       " 'horrific',\n",
       " 'abject',\n",
       " 'estimable',\n",
       " 'varicose',\n",
       " 'synthetic',\n",
       " 'superb',\n",
       " 'pernicious',\n",
       " 'infernal',\n",
       " 'unparallel',\n",
       " 'frozen',\n",
       " 'woeful',\n",
       " 'harsh',\n",
       " 'slap-up',\n",
       " 'idyllic',\n",
       " 'heartsick',\n",
       " 'miserable',\n",
       " 'pitiful',\n",
       " 'cheapjack',\n",
       " 'modest',\n",
       " 'elysian',\n",
       " 'heartbroken',\n",
       " 'bully',\n",
       " 'nasty',\n",
       " 'chintzy',\n",
       " 'mean',\n",
       " 'base',\n",
       " 'exhilarated',\n",
       " 'befouled',\n",
       " 'helpless',\n",
       " 'modified',\n",
       " 'negative',\n",
       " 'top-hole',\n",
       " 'thorny',\n",
       " 'flagrant',\n",
       " 'incumbent_on',\n",
       " 'disenchanted',\n",
       " 'sensational',\n",
       " 'foul',\n",
       " 'barren',\n",
       " 'day-old',\n",
       " 'paranormal',\n",
       " 'sterling',\n",
       " 'unauthorised',\n",
       " 'nice',\n",
       " 'maddening',\n",
       " 'horrid',\n",
       " 'reputable',\n",
       " 'rosy',\n",
       " 'inauspicious',\n",
       " 'awing',\n",
       " 'deficient',\n",
       " 'evil',\n",
       " 'unmourned',\n",
       " 'feigned',\n",
       " 'good',\n",
       " 'misfortunate',\n",
       " 'benignant',\n",
       " 'worrying',\n",
       " 'snot-nosed']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "senti_lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#map the sentiment words to integer based on vocab2int\n",
    "senti2int = [getWordIdx(word, vocab_to_int_train) for word in senti_lexicon]\n",
    "\n",
    "#get the filter weights based on the sentiment words&vocab2int&embedding_matrix\n",
    "def Find_Filter_Weight(senti2int):\n",
    "    \"\"\"sentiwords is the list\"\"\"\n",
    "    word_filter_weights = []\n",
    "    bias_weights = []\n",
    "    filter_len = 1\n",
    "    for i in senti2int:\n",
    "        vector = embedding_matrix[i]  # shape: 300\n",
    "        vector = np.expand_dims(vector, axis=0) #shape: 1x 300\n",
    "        vector = np.expand_dims(vector, axis=2) #shape: 1x 300 x 1\n",
    "        if len(word_filter_weights) == 0:\n",
    "            word_filter_weights = vector\n",
    "        else:\n",
    "            word_filter_weights = np.concatenate((word_filter_weights, vector), axis=2)   \n",
    "    #shape is (1, 300, 533)\n",
    "    \n",
    "    bias_weights = np.zeros(len(senti2int))\n",
    "    cnn_wordfilter_weights = [word_filter_weights, bias_weights]\n",
    "    \n",
    "    return cnn_wordfilter_weights    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300, 533)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN_weights = Find_Filter_Weight(senti2int)\n",
    "CNN_weights[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment \n",
    "* record the result of running the different vesions\n",
    "* change the parameter to run and record the result again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data prepocessing for CNN/GRU/LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define all of the functions\n",
    "punctuation_list = list(string.punctuation)\n",
    "\n",
    "def word_tokenize(sent):\n",
    "    tokenized_text = nltk.word_tokenize(sent)  # this gives you a list of words\n",
    "    tokenized_text = [token.lower() for token in tokenized_text if token not in punctuation_list]  # optional: convert all words to lower case\n",
    "    return tokenized_text\n",
    "\n",
    "def readfile(filename):\n",
    "    with open(filename,'r',encoding='UTF-8') as f:\n",
    "        content = f.readlines()\n",
    "    content = [x.strip() for x in content] \n",
    "    #strip()读出有效文件，形成一个list\n",
    "    #split()读成有效文件，根据一行来形成一个list\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#**********loading data\n",
    "#get the movie review \"list of string\"\n",
    "test_neg = readfile('data/aclImdb/test-neg.txt')\n",
    "test_pos = readfile('data/aclImdb/test-pos.txt')\n",
    "train_neg = readfile('data/aclImdb/train-neg.txt')\n",
    "train_pos = readfile('data/aclImdb/train-pos.txt')\n",
    "\n",
    "#use these lists to label the movie reviews\n",
    "test_neg_label = [0 for i in range(len(test_neg))]\n",
    "test_pos_label = [1 for i in range(len(test_pos))]\n",
    "train_neg_label =[0 for i in range(len(train_neg))]\n",
    "train_pos_label =[1 for i in range(len(train_pos))]\n",
    "\n",
    "\n",
    "#merge the test label\n",
    "test_label = test_neg_label + test_pos_label\n",
    "\n",
    "#merge the train label\n",
    "train_label = train_neg_label + train_pos_label\n",
    "\n",
    "#merge the test data\n",
    "test_data = test_neg + test_pos\n",
    "\n",
    "#merge the train data\n",
    "train_data = train_neg + train_pos\n",
    "\n",
    "#shuffule the these lists\n",
    "from sklearn.utils import shuffle \n",
    "train_data , train_label = shuffle(train_data , train_label , random_state = 0)\n",
    "test_data , test_label = shuffle(test_data ,test_label , random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n",
      "Pad sequences (samples x time)\n",
      "x_train shape: (25000, 224)\n",
      "x_test shape: (25000, 224)\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the data for the cnn layer\n",
    "#word tokenizing the data\n",
    "training_data = []\n",
    "for data in train_data:\n",
    "    training_data.append(word_tokenize(data))\n",
    "\n",
    "testing_data = []\n",
    "for data in test_data:\n",
    "    testing_data.append(word_tokenize(data))\n",
    "    \n",
    "#map the word to integer\n",
    "x_train = []\n",
    "word2int = []\n",
    "for review in training_data:\n",
    "    word2int =[getWordIdx(word, vocab_to_int_train) for word in review]\n",
    "    x_train.append(word2int)\n",
    "    \n",
    "x_test = []\n",
    "word2int = []\n",
    "for review in testing_data:\n",
    "    word2int = [getWordIdx(word, vocab_to_int_train) for word in review]\n",
    "    x_test.append(word2int)\n",
    "\n",
    "\n",
    "#show and padding the data\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')\n",
    "print('Pad sequences (samples x time)')\n",
    "sequence = keras.preprocessing.sequence\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=maxlen_word)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=maxlen_word)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:14: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(padding=\"same\", filters=200, activation=\"relu\", kernel_size=3, strides=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 224, 300)          30089100  \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 224, 200)          180200    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 30,289,501\n",
      "Trainable params: 200,401\n",
      "Non-trainable params: 30,089,100\n",
      "_________________________________________________________________\n",
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 231s 9ms/step - loss: 0.4968 - acc: 0.7638 - val_loss: 0.3372 - val_acc: 0.8537\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 269s 11ms/step - loss: 0.3032 - acc: 0.8736 - val_loss: 0.2970 - val_acc: 0.8725\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 227s 9ms/step - loss: 0.2449 - acc: 0.9024 - val_loss: 0.2781 - val_acc: 0.8832\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 223s 9ms/step - loss: 0.2003 - acc: 0.9249 - val_loss: 0.2692 - val_acc: 0.8871\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 209s 8ms/step - loss: 0.1547 - acc: 0.9476 - val_loss: 0.2705 - val_acc: 0.8888\n",
      "25000/25000 [==============================] - 55s 2ms/step\n",
      "Test accuracy: 0.8887999954223633\n"
     ]
    }
   ],
   "source": [
    "#build the model\n",
    "num_filter = 200\n",
    "dim = int(num_filter/2)\n",
    "batch_size = 300\n",
    "num_epoch = 5\n",
    "\n",
    "input_data = Input(shape=(maxlen_word,))\n",
    "embeded = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)(input_data)\n",
    "hidden_layer = Convolution1D(nb_filter=num_filter,\n",
    "                            filter_length=3,\n",
    "                            border_mode='same',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1\n",
    "                            )(embeded)\n",
    "cnn_out = GlobalMaxPooling1D()(hidden_layer)\n",
    "dense = Dense(dim, activation='sigmoid')(cnn_out)\n",
    "#dense = Dense(dim, activation='softmax')(cnn_out)\n",
    "Final = Dense(1,activation = 'sigmoid')(dense)#为什么换成softmax就很差\n",
    "model = Model(inputs=input_data, outputs=[Final])\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "#training the model\n",
    "print('Train...')\n",
    "model.fit(x_train, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          validation_data=(x_test, test_label))\n",
    "score, acc = model.evaluate(x_test, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)\n",
    "#the validate is too much?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 64s 3ms/step\n",
      "Accuracy: 0.8918\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.87      0.89     12500\n",
      "          1       0.88      0.91      0.89     12500\n",
      "\n",
      "avg / total       0.89      0.89      0.89     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_test_prob = model.predict(x_test, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classical LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "embedding_22 (Embedding)     (None, 224, 300)          30089100  \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               219648    \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,317,069\n",
      "Trainable params: 227,969\n",
      "Non-trainable params: 30,089,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build LSTM model\n",
    "batch_size = 200\n",
    "num_epoch = 5\n",
    "\n",
    "input_data = Input(shape=(maxlen_word,))\n",
    "embeded = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)(input_data)\n",
    "# hidden_layer = LSTM(128, activation = 'sigmoid',dropout=0.2, recurrent_dropout=0.2)(embeded)\n",
    "#hidden_layer = LSTM(128, activation = 'relu',dropout=0.2, recurrent_dropout=0.2)(embeded)\n",
    "# hidden_layer = LSTM(128, activation = 'tanh',dropout=0.1, recurrent_dropout=0.2)(embeded)\n",
    "hidden_layer = LSTM(128, activation = 'relu',dropout=0.1, recurrent_dropout=0.2)(embeded)\n",
    "dense = Dense(64,activation = 'relu')(hidden_layer)\n",
    "Final = Dense(1,activation = 'relu')(dense)\n",
    "\n",
    "#compile the model\n",
    "model = Model(inputs=[input_data], outputs=[Final])\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 2929s 117ms/step - loss: 0.6755 - acc: 0.5758 - val_loss: 0.6085 - val_acc: 0.6737\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 3702s 148ms/step - loss: nan - acc: 0.3383 - val_loss: nan - val_acc: 0.0000e+00\n",
      "Epoch 3/5\n",
      "20800/25000 [=======================>......] - ETA: 8:51 - loss: nan - acc: 0.0000e+00"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[200,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node lstm_9/while/MatMul_6}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training_15/Adam/gradients/lstm_9/while/mul_6_grad/Reshape\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_9/while/mul_6, lstm_9/while/MatMul_6/Enter)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-5faf9e62f673>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m           validation_data=(x_test, test_label))\n\u001b[0m\u001b[0;32m      9\u001b[0m score, acc = model.evaluate(x_test, test_label,\n\u001b[0;32m     10\u001b[0m                             batch_size=batch_size)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    529\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[200,128] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node lstm_9/while/MatMul_6}} = MatMul[T=DT_FLOAT, _class=[\"loc:@training_15/Adam/gradients/lstm_9/while/mul_6_grad/Reshape\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](lstm_9/while/mul_6, lstm_9/while/MatMul_6/Enter)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "print('Train...')\n",
    "model.fit(x_train, train_label,\n",
    "          batch_size=batch_size,\n",
    "\n",
    "          \n",
    "          epochs=num_epoch,\n",
    "          validation_data=(x_test, test_label))\n",
    "score, acc = model.evaluate(x_test, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#measure the model\n",
    "pred_test_prob = model.predict(x_test, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    \n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    \n",
    "    \n",
    "    \n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### classical GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 224, 300)          30089100  \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (None, 224, 128)          164736    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 224, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 224, 1)            65        \n",
      "=================================================================\n",
      "Total params: 30,262,157\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 30,089,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 224)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 224, 300)          30089100  \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 128)               164736    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 30,262,157\n",
      "Trainable params: 173,057\n",
      "Non-trainable params: 30,089,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build GRU model\n",
    "batch_size = 300\n",
    "num_epoch = 5\n",
    "\n",
    "input_data = Input(shape=(maxlen_word,))\n",
    "embeded = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)(input_data)\n",
    "hidden_layer = GRU(128, activation = 'tanh',dropout=0.1, recurrent_dropout=0.2)(embeded)\n",
    "dense = Dense(64,activation = 'relu')(hidden_layer)\n",
    "Final = Dense(1,activation = 'sigmoid')(dense)\n",
    "\n",
    "#compile the model\n",
    "model = Model(inputs=[input_data], outputs=[Final])\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 482s 19ms/step - loss: 0.5716 - acc: 0.6991 - val_loss: 0.4778 - val_acc: 0.7754\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 483s 19ms/step - loss: 0.4817 - acc: 0.7800 - val_loss: 0.3960 - val_acc: 0.8266\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 493s 20ms/step - loss: 0.3864 - acc: 0.8330 - val_loss: 0.3370 - val_acc: 0.8545\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 447s 18ms/step - loss: 0.3402 - acc: 0.8563 - val_loss: 0.3020 - val_acc: 0.8728\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 448s 18ms/step - loss: 0.3119 - acc: 0.8684 - val_loss: 0.2877 - val_acc: 0.8795\n",
      "25000/25000 [==============================] - 123s 5ms/step\n",
      "Test accuracy: 0.8795200006961823\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "print('Train...')\n",
    "model.fit(x_train, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          validation_data=(x_test, test_label))\n",
    "score, acc = model.evaluate(x_test, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 137s 5ms/step\n",
      "Accuracy: 0.8795\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.86      0.88     12500\n",
      "          1       0.86      0.90      0.88     12500\n",
      "\n",
      "avg / total       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#measure the model\n",
    "pred_test_prob = model.predict(x_test, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KCNN+GRU(The document is seperated by sentence first and then by word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=200, kernel_size=3, activation=\"relu\", padding=\"same\", strides=1)`\n",
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:25: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(filters=533, kernel_size=1, activation=\"relu\", padding=\"same\", trainable=False, weights=[array([[[..., strides=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 36, 224)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 224)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 224, 300)     30089100    lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "                                                                 lambda_5[0][0]                   \n",
      "                                                                 lambda_6[0][0]                   \n",
      "                                                                 lambda_7[0][0]                   \n",
      "                                                                 lambda_8[0][0]                   \n",
      "                                                                 lambda_9[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "                                                                 lambda_11[0][0]                  \n",
      "                                                                 lambda_12[0][0]                  \n",
      "                                                                 lambda_13[0][0]                  \n",
      "                                                                 lambda_14[0][0]                  \n",
      "                                                                 lambda_15[0][0]                  \n",
      "                                                                 lambda_16[0][0]                  \n",
      "                                                                 lambda_17[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "                                                                 lambda_19[0][0]                  \n",
      "                                                                 lambda_20[0][0]                  \n",
      "                                                                 lambda_21[0][0]                  \n",
      "                                                                 lambda_22[0][0]                  \n",
      "                                                                 lambda_23[0][0]                  \n",
      "                                                                 lambda_24[0][0]                  \n",
      "                                                                 lambda_25[0][0]                  \n",
      "                                                                 lambda_26[0][0]                  \n",
      "                                                                 lambda_27[0][0]                  \n",
      "                                                                 lambda_28[0][0]                  \n",
      "                                                                 lambda_29[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "                                                                 lambda_31[0][0]                  \n",
      "                                                                 lambda_32[0][0]                  \n",
      "                                                                 lambda_33[0][0]                  \n",
      "                                                                 lambda_34[0][0]                  \n",
      "                                                                 lambda_35[0][0]                  \n",
      "                                                                 lambda_36[0][0]                  \n",
      "                                                                 lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 224, 200)     180200      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "                                                                 embedding_1[2][0]                \n",
      "                                                                 embedding_1[3][0]                \n",
      "                                                                 embedding_1[4][0]                \n",
      "                                                                 embedding_1[5][0]                \n",
      "                                                                 embedding_1[6][0]                \n",
      "                                                                 embedding_1[7][0]                \n",
      "                                                                 embedding_1[8][0]                \n",
      "                                                                 embedding_1[9][0]                \n",
      "                                                                 embedding_1[10][0]               \n",
      "                                                                 embedding_1[11][0]               \n",
      "                                                                 embedding_1[12][0]               \n",
      "                                                                 embedding_1[13][0]               \n",
      "                                                                 embedding_1[14][0]               \n",
      "                                                                 embedding_1[15][0]               \n",
      "                                                                 embedding_1[16][0]               \n",
      "                                                                 embedding_1[17][0]               \n",
      "                                                                 embedding_1[18][0]               \n",
      "                                                                 embedding_1[19][0]               \n",
      "                                                                 embedding_1[20][0]               \n",
      "                                                                 embedding_1[21][0]               \n",
      "                                                                 embedding_1[22][0]               \n",
      "                                                                 embedding_1[23][0]               \n",
      "                                                                 embedding_1[24][0]               \n",
      "                                                                 embedding_1[25][0]               \n",
      "                                                                 embedding_1[26][0]               \n",
      "                                                                 embedding_1[27][0]               \n",
      "                                                                 embedding_1[28][0]               \n",
      "                                                                 embedding_1[29][0]               \n",
      "                                                                 embedding_1[30][0]               \n",
      "                                                                 embedding_1[31][0]               \n",
      "                                                                 embedding_1[32][0]               \n",
      "                                                                 embedding_1[33][0]               \n",
      "                                                                 embedding_1[34][0]               \n",
      "                                                                 embedding_1[35][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 224, 533)     160433      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "                                                                 embedding_1[2][0]                \n",
      "                                                                 embedding_1[3][0]                \n",
      "                                                                 embedding_1[4][0]                \n",
      "                                                                 embedding_1[5][0]                \n",
      "                                                                 embedding_1[6][0]                \n",
      "                                                                 embedding_1[7][0]                \n",
      "                                                                 embedding_1[8][0]                \n",
      "                                                                 embedding_1[9][0]                \n",
      "                                                                 embedding_1[10][0]               \n",
      "                                                                 embedding_1[11][0]               \n",
      "                                                                 embedding_1[12][0]               \n",
      "                                                                 embedding_1[13][0]               \n",
      "                                                                 embedding_1[14][0]               \n",
      "                                                                 embedding_1[15][0]               \n",
      "                                                                 embedding_1[16][0]               \n",
      "                                                                 embedding_1[17][0]               \n",
      "                                                                 embedding_1[18][0]               \n",
      "                                                                 embedding_1[19][0]               \n",
      "                                                                 embedding_1[20][0]               \n",
      "                                                                 embedding_1[21][0]               \n",
      "                                                                 embedding_1[22][0]               \n",
      "                                                                 embedding_1[23][0]               \n",
      "                                                                 embedding_1[24][0]               \n",
      "                                                                 embedding_1[25][0]               \n",
      "                                                                 embedding_1[26][0]               \n",
      "                                                                 embedding_1[27][0]               \n",
      "                                                                 embedding_1[28][0]               \n",
      "                                                                 embedding_1[29][0]               \n",
      "                                                                 embedding_1[30][0]               \n",
      "                                                                 embedding_1[31][0]               \n",
      "                                                                 embedding_1[32][0]               \n",
      "                                                                 embedding_1[33][0]               \n",
      "                                                                 embedding_1[34][0]               \n",
      "                                                                 embedding_1[35][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM multiple             0           conv1d_1[0][0]                   \n",
      "                                                                 conv1d_2[0][0]                   \n",
      "                                                                 conv1d_1[1][0]                   \n",
      "                                                                 conv1d_2[1][0]                   \n",
      "                                                                 conv1d_1[2][0]                   \n",
      "                                                                 conv1d_2[2][0]                   \n",
      "                                                                 conv1d_1[3][0]                   \n",
      "                                                                 conv1d_2[3][0]                   \n",
      "                                                                 conv1d_1[4][0]                   \n",
      "                                                                 conv1d_2[4][0]                   \n",
      "                                                                 conv1d_1[5][0]                   \n",
      "                                                                 conv1d_2[5][0]                   \n",
      "                                                                 conv1d_1[6][0]                   \n",
      "                                                                 conv1d_2[6][0]                   \n",
      "                                                                 conv1d_1[7][0]                   \n",
      "                                                                 conv1d_2[7][0]                   \n",
      "                                                                 conv1d_1[8][0]                   \n",
      "                                                                 conv1d_2[8][0]                   \n",
      "                                                                 conv1d_1[9][0]                   \n",
      "                                                                 conv1d_2[9][0]                   \n",
      "                                                                 conv1d_1[10][0]                  \n",
      "                                                                 conv1d_2[10][0]                  \n",
      "                                                                 conv1d_1[11][0]                  \n",
      "                                                                 conv1d_2[11][0]                  \n",
      "                                                                 conv1d_1[12][0]                  \n",
      "                                                                 conv1d_2[12][0]                  \n",
      "                                                                 conv1d_1[13][0]                  \n",
      "                                                                 conv1d_2[13][0]                  \n",
      "                                                                 conv1d_1[14][0]                  \n",
      "                                                                 conv1d_2[14][0]                  \n",
      "                                                                 conv1d_1[15][0]                  \n",
      "                                                                 conv1d_2[15][0]                  \n",
      "                                                                 conv1d_1[16][0]                  \n",
      "                                                                 conv1d_2[16][0]                  \n",
      "                                                                 conv1d_1[17][0]                  \n",
      "                                                                 conv1d_2[17][0]                  \n",
      "                                                                 conv1d_1[18][0]                  \n",
      "                                                                 conv1d_2[18][0]                  \n",
      "                                                                 conv1d_1[19][0]                  \n",
      "                                                                 conv1d_2[19][0]                  \n",
      "                                                                 conv1d_1[20][0]                  \n",
      "                                                                 conv1d_2[20][0]                  \n",
      "                                                                 conv1d_1[21][0]                  \n",
      "                                                                 conv1d_2[21][0]                  \n",
      "                                                                 conv1d_1[22][0]                  \n",
      "                                                                 conv1d_2[22][0]                  \n",
      "                                                                 conv1d_1[23][0]                  \n",
      "                                                                 conv1d_2[23][0]                  \n",
      "                                                                 conv1d_1[24][0]                  \n",
      "                                                                 conv1d_2[24][0]                  \n",
      "                                                                 conv1d_1[25][0]                  \n",
      "                                                                 conv1d_2[25][0]                  \n",
      "                                                                 conv1d_1[26][0]                  \n",
      "                                                                 conv1d_2[26][0]                  \n",
      "                                                                 conv1d_1[27][0]                  \n",
      "                                                                 conv1d_2[27][0]                  \n",
      "                                                                 conv1d_1[28][0]                  \n",
      "                                                                 conv1d_2[28][0]                  \n",
      "                                                                 conv1d_1[29][0]                  \n",
      "                                                                 conv1d_2[29][0]                  \n",
      "                                                                 conv1d_1[30][0]                  \n",
      "                                                                 conv1d_2[30][0]                  \n",
      "                                                                 conv1d_1[31][0]                  \n",
      "                                                                 conv1d_2[31][0]                  \n",
      "                                                                 conv1d_1[32][0]                  \n",
      "                                                                 conv1d_2[32][0]                  \n",
      "                                                                 conv1d_1[33][0]                  \n",
      "                                                                 conv1d_2[33][0]                  \n",
      "                                                                 conv1d_1[34][0]                  \n",
      "                                                                 conv1d_2[34][0]                  \n",
      "                                                                 conv1d_1[35][0]                  \n",
      "                                                                 conv1d_2[35][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_1[1][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[2][0]     \n",
      "                                                                 global_max_pooling1d_1[3][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[4][0]     \n",
      "                                                                 global_max_pooling1d_1[5][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[6][0]     \n",
      "                                                                 global_max_pooling1d_1[7][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[8][0]     \n",
      "                                                                 global_max_pooling1d_1[9][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[10][0]    \n",
      "                                                                 global_max_pooling1d_1[11][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[12][0]    \n",
      "                                                                 global_max_pooling1d_1[13][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[14][0]    \n",
      "                                                                 global_max_pooling1d_1[15][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 733)          0           global_max_pooling1d_1[16][0]    \n",
      "                                                                 global_max_pooling1d_1[17][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[18][0]    \n",
      "                                                                 global_max_pooling1d_1[19][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_11 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[20][0]    \n",
      "                                                                 global_max_pooling1d_1[21][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_12 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[22][0]    \n",
      "                                                                 global_max_pooling1d_1[23][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_13 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[24][0]    \n",
      "                                                                 global_max_pooling1d_1[25][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_14 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[26][0]    \n",
      "                                                                 global_max_pooling1d_1[27][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_15 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[28][0]    \n",
      "                                                                 global_max_pooling1d_1[29][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_16 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[30][0]    \n",
      "                                                                 global_max_pooling1d_1[31][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_17 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[32][0]    \n",
      "                                                                 global_max_pooling1d_1[33][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_18 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[34][0]    \n",
      "                                                                 global_max_pooling1d_1[35][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_19 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[36][0]    \n",
      "                                                                 global_max_pooling1d_1[37][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_20 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[38][0]    \n",
      "                                                                 global_max_pooling1d_1[39][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_21 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[40][0]    \n",
      "                                                                 global_max_pooling1d_1[41][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_22 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[42][0]    \n",
      "                                                                 global_max_pooling1d_1[43][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_23 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[44][0]    \n",
      "                                                                 global_max_pooling1d_1[45][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_24 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[46][0]    \n",
      "                                                                 global_max_pooling1d_1[47][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_25 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[48][0]    \n",
      "                                                                 global_max_pooling1d_1[49][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_26 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[50][0]    \n",
      "                                                                 global_max_pooling1d_1[51][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_27 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[52][0]    \n",
      "                                                                 global_max_pooling1d_1[53][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_28 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[54][0]    \n",
      "                                                                 global_max_pooling1d_1[55][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_29 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[56][0]    \n",
      "                                                                 global_max_pooling1d_1[57][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_30 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[58][0]    \n",
      "                                                                 global_max_pooling1d_1[59][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[60][0]    \n",
      "                                                                 global_max_pooling1d_1[61][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[62][0]    \n",
      "                                                                 global_max_pooling1d_1[63][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[64][0]    \n",
      "                                                                 global_max_pooling1d_1[65][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_34 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[66][0]    \n",
      "                                                                 global_max_pooling1d_1[67][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_35 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[68][0]    \n",
      "                                                                 global_max_pooling1d_1[69][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_36 (Concatenate)    (None, 733)          0           global_max_pooling1d_1[70][0]    \n",
      "                                                                 global_max_pooling1d_1[71][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 36, 733)      0           concatenate_1[0][0]              \n",
      "                                                                 concatenate_2[0][0]              \n",
      "                                                                 concatenate_3[0][0]              \n",
      "                                                                 concatenate_4[0][0]              \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 concatenate_8[0][0]              \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 concatenate_11[0][0]             \n",
      "                                                                 concatenate_12[0][0]             \n",
      "                                                                 concatenate_13[0][0]             \n",
      "                                                                 concatenate_14[0][0]             \n",
      "                                                                 concatenate_15[0][0]             \n",
      "                                                                 concatenate_16[0][0]             \n",
      "                                                                 concatenate_17[0][0]             \n",
      "                                                                 concatenate_18[0][0]             \n",
      "                                                                 concatenate_19[0][0]             \n",
      "                                                                 concatenate_20[0][0]             \n",
      "                                                                 concatenate_21[0][0]             \n",
      "                                                                 concatenate_22[0][0]             \n",
      "                                                                 concatenate_23[0][0]             \n",
      "                                                                 concatenate_24[0][0]             \n",
      "                                                                 concatenate_25[0][0]             \n",
      "                                                                 concatenate_26[0][0]             \n",
      "                                                                 concatenate_27[0][0]             \n",
      "                                                                 concatenate_28[0][0]             \n",
      "                                                                 concatenate_29[0][0]             \n",
      "                                                                 concatenate_30[0][0]             \n",
      "                                                                 concatenate_31[0][0]             \n",
      "                                                                 concatenate_32[0][0]             \n",
      "                                                                 concatenate_33[0][0]             \n",
      "                                                                 concatenate_34[0][0]             \n",
      "                                                                 concatenate_35[0][0]             \n",
      "                                                                 concatenate_36[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (None, 256)          760320      lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          32896       gru_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 31,223,078\n",
      "Trainable params: 973,545\n",
      "Non-trainable params: 30,249,533\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the kCNN+GRU model\n",
    "def slice(x, index):\n",
    "    \"\"\" Define a tensor slice function\n",
    "    \n",
    "    \"\"\"\n",
    "    return x[:, index, :]\n",
    "\n",
    "\n",
    "\n",
    "input_data = Input(shape = (maxlen_sent,maxlen_word))\n",
    "embedding_layer = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)\n",
    "cnn_layer1 = Convolution1D(nb_filter=200,\n",
    "                            filter_length=3,\n",
    "                            border_mode='same',\n",
    "                            activation='relu',\n",
    "                            subsample_length=1)\n",
    "\n",
    "cnn_layer2 = Convolution1D(nb_filter=CNN_weights[0].shape[2],\n",
    "                            filter_length=1,\n",
    "                            border_mode='same',\n",
    "                            activation='relu',\n",
    "                           weights = CNN_weights,\n",
    "                           trainable = False,\n",
    "                            subsample_length=1)\n",
    "\n",
    "#embedding matrix shape[1]是300，每个vector的维度\n",
    "max_pooling_layer = GlobalMaxPooling1D()\n",
    "\n",
    "#************\n",
    "stack_layer = Lambda(lambda x: K.stack(x, axis=1))\n",
    "\n",
    "# interate through sentences in a document\n",
    "cnn_out = []\n",
    "for i in range(maxlen_sent):\n",
    "    #以每个影评的每个句子为输入\n",
    "    sent = Lambda(slice, arguments={'index': i,})(input_data)#use the lambda to enclose the function as the slicing layer\n",
    "    sent_embedding = embedding_layer(sent)#input shape:(padded_sentence_number),output shape:(nb_words_padded,dimension)\n",
    "    \n",
    "    sent_cnn1 = cnn_layer1(sent_embedding) # output shape: (None, maxlen_word, nb_filter)\n",
    "    # we use standard max over time pooling\n",
    "    sent_cnn1 = max_pooling_layer(sent_cnn1)  # output shape: (None, nb_filter)\n",
    "    \n",
    "    sent_cnn2 = cnn_layer2(sent_embedding) # output shape: (None, maxlen_word, nb_filter)\n",
    "    # we use standard max over time pooling\n",
    "    sent_cnn2 = max_pooling_layer(sent_cnn2)  # output shape: (None, nb_filter)\n",
    "    \n",
    "    sent_cnn = concatenate([sent_cnn1, sent_cnn2])\n",
    "    \n",
    "    cnn_out.append(sent_cnn)\n",
    "cnn_out = stack_layer(cnn_out)  # out shape: (None, maxlen_sent, nb_filter)\n",
    "\n",
    "\n",
    "\n",
    "#处理句子，从头到尾\n",
    "gru= GRU(256, dropout=0.3, recurrent_dropout=0.2)(cnn_out)\n",
    "dense1 = Dense(128, activation='sigmoid')(gru)\n",
    "Final = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "model = Model(inputs=[input_data], outputs=[Final])\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "batch_size = 300\n",
    "num_epoch = 5\n",
    "\n",
    "print('Training...')\n",
    "model.fit(train_copus_padded, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=num_epoch,\n",
    "          validation_data=(test_copus_padded, test_label))\n",
    "\n",
    "score, acc = model.evaluate(test_copus_padded, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#measure the model\n",
    "pred_test_prob = model.predict(test_copus_padded, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "### GRU+CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:22: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=3, filters=100, activation=\"tanh\", strides=1, padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_data (InputLayer)         (None, 36, 224)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_298 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_299 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_300 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_301 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_302 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_303 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_304 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_305 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_306 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_307 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_308 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_309 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_310 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_311 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_312 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_313 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_314 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_315 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_316 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_317 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_318 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_319 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_320 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_321 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_322 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_323 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_324 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_325 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_326 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_327 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_328 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_329 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_330 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_331 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_332 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_333 (Lambda)             (None, 224)          0           input_data[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "embedding_12 (Embedding)        (None, 224, 300)     30089100    lambda_298[0][0]                 \n",
      "                                                                 lambda_299[0][0]                 \n",
      "                                                                 lambda_300[0][0]                 \n",
      "                                                                 lambda_301[0][0]                 \n",
      "                                                                 lambda_302[0][0]                 \n",
      "                                                                 lambda_303[0][0]                 \n",
      "                                                                 lambda_304[0][0]                 \n",
      "                                                                 lambda_305[0][0]                 \n",
      "                                                                 lambda_306[0][0]                 \n",
      "                                                                 lambda_307[0][0]                 \n",
      "                                                                 lambda_308[0][0]                 \n",
      "                                                                 lambda_309[0][0]                 \n",
      "                                                                 lambda_310[0][0]                 \n",
      "                                                                 lambda_311[0][0]                 \n",
      "                                                                 lambda_312[0][0]                 \n",
      "                                                                 lambda_313[0][0]                 \n",
      "                                                                 lambda_314[0][0]                 \n",
      "                                                                 lambda_315[0][0]                 \n",
      "                                                                 lambda_316[0][0]                 \n",
      "                                                                 lambda_317[0][0]                 \n",
      "                                                                 lambda_318[0][0]                 \n",
      "                                                                 lambda_319[0][0]                 \n",
      "                                                                 lambda_320[0][0]                 \n",
      "                                                                 lambda_321[0][0]                 \n",
      "                                                                 lambda_322[0][0]                 \n",
      "                                                                 lambda_323[0][0]                 \n",
      "                                                                 lambda_324[0][0]                 \n",
      "                                                                 lambda_325[0][0]                 \n",
      "                                                                 lambda_326[0][0]                 \n",
      "                                                                 lambda_327[0][0]                 \n",
      "                                                                 lambda_328[0][0]                 \n",
      "                                                                 lambda_329[0][0]                 \n",
      "                                                                 lambda_330[0][0]                 \n",
      "                                                                 lambda_331[0][0]                 \n",
      "                                                                 lambda_332[0][0]                 \n",
      "                                                                 lambda_333[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "gru_11 (GRU)                    (None, 128)          164736      embedding_12[0][0]               \n",
      "                                                                 embedding_12[1][0]               \n",
      "                                                                 embedding_12[2][0]               \n",
      "                                                                 embedding_12[3][0]               \n",
      "                                                                 embedding_12[4][0]               \n",
      "                                                                 embedding_12[5][0]               \n",
      "                                                                 embedding_12[6][0]               \n",
      "                                                                 embedding_12[7][0]               \n",
      "                                                                 embedding_12[8][0]               \n",
      "                                                                 embedding_12[9][0]               \n",
      "                                                                 embedding_12[10][0]              \n",
      "                                                                 embedding_12[11][0]              \n",
      "                                                                 embedding_12[12][0]              \n",
      "                                                                 embedding_12[13][0]              \n",
      "                                                                 embedding_12[14][0]              \n",
      "                                                                 embedding_12[15][0]              \n",
      "                                                                 embedding_12[16][0]              \n",
      "                                                                 embedding_12[17][0]              \n",
      "                                                                 embedding_12[18][0]              \n",
      "                                                                 embedding_12[19][0]              \n",
      "                                                                 embedding_12[20][0]              \n",
      "                                                                 embedding_12[21][0]              \n",
      "                                                                 embedding_12[22][0]              \n",
      "                                                                 embedding_12[23][0]              \n",
      "                                                                 embedding_12[24][0]              \n",
      "                                                                 embedding_12[25][0]              \n",
      "                                                                 embedding_12[26][0]              \n",
      "                                                                 embedding_12[27][0]              \n",
      "                                                                 embedding_12[28][0]              \n",
      "                                                                 embedding_12[29][0]              \n",
      "                                                                 embedding_12[30][0]              \n",
      "                                                                 embedding_12[31][0]              \n",
      "                                                                 embedding_12[32][0]              \n",
      "                                                                 embedding_12[33][0]              \n",
      "                                                                 embedding_12[34][0]              \n",
      "                                                                 embedding_12[35][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_297 (Lambda)             (None, 36, 128)      0           gru_11[0][0]                     \n",
      "                                                                 gru_11[1][0]                     \n",
      "                                                                 gru_11[2][0]                     \n",
      "                                                                 gru_11[3][0]                     \n",
      "                                                                 gru_11[4][0]                     \n",
      "                                                                 gru_11[5][0]                     \n",
      "                                                                 gru_11[6][0]                     \n",
      "                                                                 gru_11[7][0]                     \n",
      "                                                                 gru_11[8][0]                     \n",
      "                                                                 gru_11[9][0]                     \n",
      "                                                                 gru_11[10][0]                    \n",
      "                                                                 gru_11[11][0]                    \n",
      "                                                                 gru_11[12][0]                    \n",
      "                                                                 gru_11[13][0]                    \n",
      "                                                                 gru_11[14][0]                    \n",
      "                                                                 gru_11[15][0]                    \n",
      "                                                                 gru_11[16][0]                    \n",
      "                                                                 gru_11[17][0]                    \n",
      "                                                                 gru_11[18][0]                    \n",
      "                                                                 gru_11[19][0]                    \n",
      "                                                                 gru_11[20][0]                    \n",
      "                                                                 gru_11[21][0]                    \n",
      "                                                                 gru_11[22][0]                    \n",
      "                                                                 gru_11[23][0]                    \n",
      "                                                                 gru_11[24][0]                    \n",
      "                                                                 gru_11[25][0]                    \n",
      "                                                                 gru_11[26][0]                    \n",
      "                                                                 gru_11[27][0]                    \n",
      "                                                                 gru_11[28][0]                    \n",
      "                                                                 gru_11[29][0]                    \n",
      "                                                                 gru_11[30][0]                    \n",
      "                                                                 gru_11[31][0]                    \n",
      "                                                                 gru_11[32][0]                    \n",
      "                                                                 gru_11[33][0]                    \n",
      "                                                                 gru_11[34][0]                    \n",
      "                                                                 gru_11[35][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 36, 100)      38500       lambda_297[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_9 (GlobalM (None, 100)          0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 50)           5050        global_max_pooling1d_9[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 1)            51          dense_17[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 30,297,437\n",
      "Trainable params: 208,337\n",
      "Non-trainable params: 30,089,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the GRU+CNN model\n",
    "batch_size = 100\n",
    "num_epoch = 5\n",
    "\n",
    "def slice(x, index):\n",
    "    \"\"\" Define a tensor slice function\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    return x[:, index, :]\n",
    "\n",
    "\n",
    "\n",
    "input_data = Input(shape = (maxlen_sent,maxlen_word), dtype='int32', name='input_data')\n",
    "embedding_layer = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)\n",
    "gru_layer = GRU(128, activation = 'tanh',dropout=0.2, recurrent_dropout=0.2)#when return_sequences=true,the lstm model returns the outputs of every timestep\n",
    "cnn_layer = Convolution1D(nb_filter=100,\n",
    "                            filter_length=3,\n",
    "                            border_mode='same',\n",
    "                            activation='tanh',\n",
    "                            subsample_length=1)\n",
    "\n",
    "#embedding matrix shape[1]是300，每个vector的维度\n",
    "max_pooling_layer = GlobalMaxPooling1D()\n",
    "\n",
    "#************\n",
    "stack_layer = Lambda(lambda x: K.stack(x, axis=1))\n",
    "\n",
    "# interate through sentences in a document\n",
    "gru_out = []\n",
    "for i in range(maxlen_sent):\n",
    "    #以每个影评的每个句子为输入\n",
    "    sent = Lambda(slice, arguments={'index': i,})(input_data)#use the lambda to enclose the function as the slicing layer\n",
    "    sent_embedding = embedding_layer(sent)#input shape:(padded_sentence_number),output shape:(nb_words_padded,dimension)\n",
    "    sent_gru = gru_layer(sent_embedding) # output shape: (None, maxlen_word, nb_filter)\n",
    "    gru_out.append(sent_gru)\n",
    "gru_out = stack_layer(gru_out)  # out shape: (None, maxlen_sent, nb_filter)\n",
    "\n",
    "\n",
    "#\n",
    "#处理句子，从头到尾\n",
    "sent_cnn = cnn_layer(gru_out)\n",
    "cnn_out = max_pooling_layer(sent_cnn)\n",
    "dense1 = Dense(50,activation='sigmoid')(cnn_out)\n",
    "dense2 = Dense(1, activation='sigmoid')(dense1)\n",
    "\n",
    "model = Model(inputs=[input_data], outputs=[dense2])\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "print('Training...')\n",
    "model.fit(train_copus_padded, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=5,\n",
    "          validation_data=(test_copus_padded, test_label))\n",
    "\n",
    "score, acc = model.evaluate(test_copus_padded, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#measure the model\n",
    "pred_test_prob = model.predict(x_test, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN+GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\__main__.py:17: UserWarning: Update your `Conv1D` call to the Keras 2 API: `Conv1D(kernel_size=3, filters=100, activation=\"tanh\", strides=1, padding=\"same\")`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 36, 224)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_190 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_192 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_193 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_194 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_195 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_198 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_199 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_200 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_202 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_203 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_204 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_205 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_207 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_208 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_209 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_210 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_211 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_212 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_213 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_214 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_215 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_216 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_217 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_218 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_219 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_220 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_221 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_222 (Lambda)             (None, 224)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 224, 300)     30089100    lambda_187[0][0]                 \n",
      "                                                                 lambda_188[0][0]                 \n",
      "                                                                 lambda_189[0][0]                 \n",
      "                                                                 lambda_190[0][0]                 \n",
      "                                                                 lambda_191[0][0]                 \n",
      "                                                                 lambda_192[0][0]                 \n",
      "                                                                 lambda_193[0][0]                 \n",
      "                                                                 lambda_194[0][0]                 \n",
      "                                                                 lambda_195[0][0]                 \n",
      "                                                                 lambda_196[0][0]                 \n",
      "                                                                 lambda_197[0][0]                 \n",
      "                                                                 lambda_198[0][0]                 \n",
      "                                                                 lambda_199[0][0]                 \n",
      "                                                                 lambda_200[0][0]                 \n",
      "                                                                 lambda_201[0][0]                 \n",
      "                                                                 lambda_202[0][0]                 \n",
      "                                                                 lambda_203[0][0]                 \n",
      "                                                                 lambda_204[0][0]                 \n",
      "                                                                 lambda_205[0][0]                 \n",
      "                                                                 lambda_206[0][0]                 \n",
      "                                                                 lambda_207[0][0]                 \n",
      "                                                                 lambda_208[0][0]                 \n",
      "                                                                 lambda_209[0][0]                 \n",
      "                                                                 lambda_210[0][0]                 \n",
      "                                                                 lambda_211[0][0]                 \n",
      "                                                                 lambda_212[0][0]                 \n",
      "                                                                 lambda_213[0][0]                 \n",
      "                                                                 lambda_214[0][0]                 \n",
      "                                                                 lambda_215[0][0]                 \n",
      "                                                                 lambda_216[0][0]                 \n",
      "                                                                 lambda_217[0][0]                 \n",
      "                                                                 lambda_218[0][0]                 \n",
      "                                                                 lambda_219[0][0]                 \n",
      "                                                                 lambda_220[0][0]                 \n",
      "                                                                 lambda_221[0][0]                 \n",
      "                                                                 lambda_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 224, 100)     90100       embedding_9[0][0]                \n",
      "                                                                 embedding_9[1][0]                \n",
      "                                                                 embedding_9[2][0]                \n",
      "                                                                 embedding_9[3][0]                \n",
      "                                                                 embedding_9[4][0]                \n",
      "                                                                 embedding_9[5][0]                \n",
      "                                                                 embedding_9[6][0]                \n",
      "                                                                 embedding_9[7][0]                \n",
      "                                                                 embedding_9[8][0]                \n",
      "                                                                 embedding_9[9][0]                \n",
      "                                                                 embedding_9[10][0]               \n",
      "                                                                 embedding_9[11][0]               \n",
      "                                                                 embedding_9[12][0]               \n",
      "                                                                 embedding_9[13][0]               \n",
      "                                                                 embedding_9[14][0]               \n",
      "                                                                 embedding_9[15][0]               \n",
      "                                                                 embedding_9[16][0]               \n",
      "                                                                 embedding_9[17][0]               \n",
      "                                                                 embedding_9[18][0]               \n",
      "                                                                 embedding_9[19][0]               \n",
      "                                                                 embedding_9[20][0]               \n",
      "                                                                 embedding_9[21][0]               \n",
      "                                                                 embedding_9[22][0]               \n",
      "                                                                 embedding_9[23][0]               \n",
      "                                                                 embedding_9[24][0]               \n",
      "                                                                 embedding_9[25][0]               \n",
      "                                                                 embedding_9[26][0]               \n",
      "                                                                 embedding_9[27][0]               \n",
      "                                                                 embedding_9[28][0]               \n",
      "                                                                 embedding_9[29][0]               \n",
      "                                                                 embedding_9[30][0]               \n",
      "                                                                 embedding_9[31][0]               \n",
      "                                                                 embedding_9[32][0]               \n",
      "                                                                 embedding_9[33][0]               \n",
      "                                                                 embedding_9[34][0]               \n",
      "                                                                 embedding_9[35][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_6 (GlobalM (None, 100)          0           conv1d_6[0][0]                   \n",
      "                                                                 conv1d_6[1][0]                   \n",
      "                                                                 conv1d_6[2][0]                   \n",
      "                                                                 conv1d_6[3][0]                   \n",
      "                                                                 conv1d_6[4][0]                   \n",
      "                                                                 conv1d_6[5][0]                   \n",
      "                                                                 conv1d_6[6][0]                   \n",
      "                                                                 conv1d_6[7][0]                   \n",
      "                                                                 conv1d_6[8][0]                   \n",
      "                                                                 conv1d_6[9][0]                   \n",
      "                                                                 conv1d_6[10][0]                  \n",
      "                                                                 conv1d_6[11][0]                  \n",
      "                                                                 conv1d_6[12][0]                  \n",
      "                                                                 conv1d_6[13][0]                  \n",
      "                                                                 conv1d_6[14][0]                  \n",
      "                                                                 conv1d_6[15][0]                  \n",
      "                                                                 conv1d_6[16][0]                  \n",
      "                                                                 conv1d_6[17][0]                  \n",
      "                                                                 conv1d_6[18][0]                  \n",
      "                                                                 conv1d_6[19][0]                  \n",
      "                                                                 conv1d_6[20][0]                  \n",
      "                                                                 conv1d_6[21][0]                  \n",
      "                                                                 conv1d_6[22][0]                  \n",
      "                                                                 conv1d_6[23][0]                  \n",
      "                                                                 conv1d_6[24][0]                  \n",
      "                                                                 conv1d_6[25][0]                  \n",
      "                                                                 conv1d_6[26][0]                  \n",
      "                                                                 conv1d_6[27][0]                  \n",
      "                                                                 conv1d_6[28][0]                  \n",
      "                                                                 conv1d_6[29][0]                  \n",
      "                                                                 conv1d_6[30][0]                  \n",
      "                                                                 conv1d_6[31][0]                  \n",
      "                                                                 conv1d_6[32][0]                  \n",
      "                                                                 conv1d_6[33][0]                  \n",
      "                                                                 conv1d_6[34][0]                  \n",
      "                                                                 conv1d_6[35][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)             (None, 36, 100)      0           global_max_pooling1d_6[0][0]     \n",
      "                                                                 global_max_pooling1d_6[1][0]     \n",
      "                                                                 global_max_pooling1d_6[2][0]     \n",
      "                                                                 global_max_pooling1d_6[3][0]     \n",
      "                                                                 global_max_pooling1d_6[4][0]     \n",
      "                                                                 global_max_pooling1d_6[5][0]     \n",
      "                                                                 global_max_pooling1d_6[6][0]     \n",
      "                                                                 global_max_pooling1d_6[7][0]     \n",
      "                                                                 global_max_pooling1d_6[8][0]     \n",
      "                                                                 global_max_pooling1d_6[9][0]     \n",
      "                                                                 global_max_pooling1d_6[10][0]    \n",
      "                                                                 global_max_pooling1d_6[11][0]    \n",
      "                                                                 global_max_pooling1d_6[12][0]    \n",
      "                                                                 global_max_pooling1d_6[13][0]    \n",
      "                                                                 global_max_pooling1d_6[14][0]    \n",
      "                                                                 global_max_pooling1d_6[15][0]    \n",
      "                                                                 global_max_pooling1d_6[16][0]    \n",
      "                                                                 global_max_pooling1d_6[17][0]    \n",
      "                                                                 global_max_pooling1d_6[18][0]    \n",
      "                                                                 global_max_pooling1d_6[19][0]    \n",
      "                                                                 global_max_pooling1d_6[20][0]    \n",
      "                                                                 global_max_pooling1d_6[21][0]    \n",
      "                                                                 global_max_pooling1d_6[22][0]    \n",
      "                                                                 global_max_pooling1d_6[23][0]    \n",
      "                                                                 global_max_pooling1d_6[24][0]    \n",
      "                                                                 global_max_pooling1d_6[25][0]    \n",
      "                                                                 global_max_pooling1d_6[26][0]    \n",
      "                                                                 global_max_pooling1d_6[27][0]    \n",
      "                                                                 global_max_pooling1d_6[28][0]    \n",
      "                                                                 global_max_pooling1d_6[29][0]    \n",
      "                                                                 global_max_pooling1d_6[30][0]    \n",
      "                                                                 global_max_pooling1d_6[31][0]    \n",
      "                                                                 global_max_pooling1d_6[32][0]    \n",
      "                                                                 global_max_pooling1d_6[33][0]    \n",
      "                                                                 global_max_pooling1d_6[34][0]    \n",
      "                                                                 global_max_pooling1d_6[35][0]    \n",
      "__________________________________________________________________________________________________\n",
      "gru_8 (GRU)                     (None, 128)          87936       lambda_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           8256        gru_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            65          dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 30,275,457\n",
      "Trainable params: 186,357\n",
      "Non-trainable params: 30,089,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#build the CNN+GRU model\n",
    "def slice(x, index):\n",
    "    \"\"\" Define a tensor slice function\n",
    "    \n",
    "    \"\"\"\n",
    "    return x[:, index, :]\n",
    "\n",
    "\n",
    "\n",
    "input_data = Input(shape = (maxlen_sent,maxlen_word))\n",
    "embedding_layer = Embedding(vocab_size, embedding_matrix.shape[1], input_length=maxlen_word, \n",
    "                            weights=[embedding_matrix], trainable=False)\n",
    "cnn_layer = Convolution1D(nb_filter=100,\n",
    "                            filter_length=3,\n",
    "                            border_mode='same',\n",
    "                            activation='tanh',\n",
    "                            subsample_length=1)\n",
    "\n",
    "#embedding matrix shape[1]是300，每个vector的维度\n",
    "max_pooling_layer = GlobalMaxPooling1D()\n",
    "\n",
    "#************\n",
    "stack_layer = Lambda(lambda x: K.stack(x, axis=1))\n",
    "\n",
    "# interate through sentences in a document\n",
    "cnn_out = []\n",
    "for i in range(maxlen_sent):\n",
    "    #以每个影评的每个句子为输入\n",
    "    sent = Lambda(slice, arguments={'index': i,})(input_data)#use the lambda to enclose the function as the slicing layer\n",
    "    sent_embedding = embedding_layer(sent)#input shape:(padded_sentence_number),output shape:(nb_words_padded,dimension)\n",
    "    \n",
    "    sent_cnn = cnn_layer(sent_embedding) # output shape: (None, maxlen_word, nb_filter)\n",
    "    # we use standard max over time pooling\n",
    "    sent_cnn = max_pooling_layer(sent_cnn)  # output shape: (None, nb_filter)\n",
    "    \n",
    "    cnn_out.append(sent_cnn)\n",
    "cnn_out = stack_layer(cnn_out)  # out shape: (None, maxlen_sent, nb_filter)\n",
    "\n",
    "\n",
    "\n",
    "#处理句子，从头到尾\n",
    "gru= GRU(128, dropout=0.2, recurrent_dropout=0.2)(cnn_out)\n",
    "dense1 = Dense(64, activation='sigmoid')(gru)\n",
    "dense2 = Dense(1,activation='sigmoid')(dense1)\n",
    "\n",
    "model = Model(inputs=[input_data], outputs=[dense2])\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/5\n",
      "25000/25000 [==============================] - 4838s 194ms/step - loss: 0.4476 - acc: 0.7849 - val_loss: 0.3210 - val_acc: 0.8656\n",
      "Epoch 2/5\n",
      "25000/25000 [==============================] - 5059s 202ms/step - loss: 0.2933 - acc: 0.8813 - val_loss: 0.3004 - val_acc: 0.8746\n",
      "Epoch 3/5\n",
      "25000/25000 [==============================] - 5907s 236ms/step - loss: 0.2484 - acc: 0.9029 - val_loss: 0.2544 - val_acc: 0.8926\n",
      "Epoch 4/5\n",
      "25000/25000 [==============================] - 5209s 208ms/step - loss: 0.2162 - acc: 0.9170 - val_loss: 0.2766 - val_acc: 0.8825\n",
      "Epoch 5/5\n",
      "25000/25000 [==============================] - 4971s 199ms/step - loss: 0.1839 - acc: 0.9313 - val_loss: 0.2470 - val_acc: 0.8966\n",
      "25000/25000 [==============================] - 1118s 45ms/step\n",
      "Test accuracy: 0.896639997959137\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "batch_size = 200\n",
    "epoch_num = 5\n",
    "\n",
    "print('Training...')\n",
    "model.fit(train_copus_padded, train_label,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epoch_num,\n",
    "          validation_data=(test_copus_padded, test_label))\n",
    "\n",
    "score, acc = model.evaluate(test_copus_padded, test_label,\n",
    "                            batch_size=batch_size)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1140s 46ms/step\n",
      "Accuracy: 0.8966\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90     12500\n",
      "          1       0.92      0.87      0.89     12500\n",
      "\n",
      "avg / total       0.90      0.90      0.90     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#measure the model\n",
    "pred_test_prob = model.predict(test_copus_padded, batch_size=batch_size, verbose=True)\n",
    "# predict the class label\n",
    "if pred_test_prob.shape[-1]>1:\n",
    "    pred_test = pred_test_prob.argmax(axis=-1)\n",
    "else:\n",
    "    pred_test = (pred_test_prob>0.5).astype('int32')\n",
    "    pred_test = pred_test.reshape(pred_test.shape[0])\n",
    "\n",
    "acc = np.sum(pred_test == test_label) / float(len(test_label))\n",
    "\n",
    "print(\"Accuracy: %.4f\" % (acc))   \n",
    "\n",
    "print(classification_report(test_label, pred_test, labels=[0, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### paper\n",
    "* 单纯用cnn只能抓到n gram的信息，没办法拿到句子和句子的semantic relation\n",
    "* 单纯用rnn同理，rnn 处理long term dependency有局限，导致前面的内容没办法没model所抓取。\n",
    "* GRU>LSTM，后面的组合用gru\n",
    "* 不分句没办法抓取semantic relation,reference document paper,记录为什么要分句（层级word(hieratical)）\n",
    "* cnn+gru(cnn先抓取句子中重要的sentiment feature,rnn抓取每个句子之间的关系，最后输出feature vector)\n",
    "* gru+cnn(gru先抓取句子中的词语之间的序列关系，cnn再抓取重要的句子(gru_output)，但是不能拿到句子和句子之间的semantic relation，结果较差)\n",
    "* Kcnn+gru(加入eternel knowledge(extracting sentiword from SentiWordNet)，为了提升cnn+gru中cnn抓取sentiment word的能力，)，reference 老师paper\n",
    "* cnn+gru单纯based on data，所以model需要大量的high quality labelled data去学习（局限），会出现overfitting(training data少，或者质量不好)\n",
    "* KCNN+gru加入human knowledge，construct sentiment word filters for cnn，更有效地提取sentiment Word,minimize reliance on training data\n",
    "* rule-based的方法很难建立，其次在改的时候也需要改一连串的规则\n",
    "* DL语言的复杂性造成data很多，很难获取\n",
    "* DL的overfitting\n",
    "* NLP tookits, POS tagger(词性)\n",
    "* 实验调整filter 10~100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### how to write paper\n",
    "* 阅读paper\n",
    "* abstract+conclusion\n",
    "* 归类（based on data(传统ML for sentiment analysis,DL_NN for sentiment analysis,cnn/rnn/combination of cnn+rnn）,+externel knowledge,sentimentWordNet)),记录每个method的局限。ML 需要复杂的feature engineering，需要externel NLP toolkits（不完美）,会出现error，影响model，DL 过于依赖大量label data，记录externel knowledge method如何使用sentiwordnet,大部分可能是使用pattern matching,our model 优势把sentiment words 融入cnn中，instead of hard mapping words.word filter* word,和word_embedding 相似，输入越大，除了能抓取sentiment word net里面的senti words,还能抓到和sentiment word相似的senti words.因为filter 基于Word embedding，做convolution的时候拿到sentiment words和input words,similarity\n",
    "* reference 对应会议 reference style\n",
    "* 记录paper怎么做的，和limitation，和我们怎么改变的？\n",
    "* kcnn  filter parameter 少，random 的少"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
